豆瓣电影短评爬虫

✨ 项目亮点
智能断点续爬：程序会智能记录上次的爬取进度，即使意外中断，下次也能从上次停止的位置继续，无需从头开始。

模块化设计：代码结构清晰，每个模块（请求、解析、存储等）各司其职，方便维护和功能扩展。

健壮的反爬机制：内置多种反爬策略，如用户代理伪装、随机延迟和多次重试，有效应对网站的限制。

⚙️ 项目结构
main.py：项目的核心入口。运行此文件即可启动整个爬虫流程。

config.py：项目的配置中心。所有可配置的参数，例如电影ID和爬取页数，都集中在此。

crawler.py：爬虫核心逻辑。包含了主要的爬取循环和流程控制。

request_module.py：网络请求模块。负责发送 HTTP 请求，并集成反爬机制。

parser_module.py：HTML 解析模块。专门用于从网页中提取评论、评分等数据。

storage_module.py：数据存储模块。负责将爬取的数据保存为 .json 和 .csv 格式。

🚀 如何使用
1. 安装项目依赖
请确保你已安装以下 Python 库：

requests

beautifulsoup4

你可以使用以下命令来安装它们：

pip install requests beautifulsoup4

2. 配置你的 Cookie
由于豆瓣有严格的反爬机制，为了顺利爬取数据，需要提供一个有效的登录 Cookie。

请在 config.py 文件中找到 RAW_COOKIE_STRING 变量，并将你的豆瓣登录 Cookie 粘贴到其中。

# config.py
RAW_COOKIE_STRING = '将你的完整Cookie字符串粘贴到这里'

3. 运行爬虫
在项目目录下，通过命令行运行 main.py 文件：

python main.py

当程序启动时，它会自动检测是否有之前中断的爬取进度，并提示你是否继续。

数据保存：爬取到的评论数据将自动保存在项目根目录下的 data 文件夹中，以 .json 和 .csv 格式呈现。

爬取限制：请注意，即使提供了 Cookie，由于网站限制，通常最多只能爬取到 400 条左右的评论。在未提供有效 Cookie 的情况下，这个限制会更严格（通常最多100条）。

应对人机验证：如果在爬取过程中遇到 403 错误或程序中断，很可能是你的 IP 被识别为机器人。此时，最有效的解决方法是手动在浏览器中访问豆瓣网站，完成人机验证，或者更换一个有效的登录 Cookie。