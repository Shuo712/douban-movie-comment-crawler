# 豆瓣电影短评爬虫

## ✨ 项目亮点

- **智能断点续爬**：程序会智能记录上次的爬取进度，即使意外中断，下次也能从上次停止的位置继续，无需从头开始。
- **模块化设计**：代码结构清晰，每个模块（请求、解析、存储等）各司其职，方便维护和功能扩展。
- **健壮的反爬机制**：内置多种反爬策略，如用户代理伪装、随机延迟和多次重试，有效应对网站的限制。

## ⚙️ 项目结构

```
├── main.py              # 项目核心入口，运行此文件启动整个爬虫流程
├── config.py            # 项目配置中心，包含所有可配置参数（电影ID、爬取页数等）
├── crawler.py           # 爬虫核心逻辑，包含主要的爬取循环和流程控制
├── request_module.py    # 网络请求模块，负责发送HTTP请求并集成反爬机制
├── parser_module.py     # HTML解析模块，用于从网页中提取评论、评分等数据
└── storage_module.py    # 数据存储模块，负责将爬取的数据保存为JSON和CSV格式
```

## 🚀 如何使用

### 1. 安装项目依赖

请确保你已安装以下Python库：

- `requests`
- `beautifulsoup4`

你可以使用以下命令来安装它们：

```bash
pip install requests beautifulsoup4
```

### 2. 配置你的Cookie

由于豆瓣有严格的反爬机制，为了顺利爬取数据，需要提供一个有效的登录Cookie。

请在`config.py`文件中找到`RAW_COOKIE_STRING`变量，并将你的豆瓣登录Cookie粘贴到其中：

```python
# config.py
RAW_COOKIE_STRING = '将你的完整Cookie字符串粘贴到这里'
```

### 3. 运行爬虫

在项目目录下，通过命令行运行`main.py`文件：

```bash
python main.py
```

当程序启动时，它会自动检测是否有之前中断的爬取进度，并提示你是否继续。

## 📝 注意事项

- **数据保存**：爬取到的评论数据将自动保存在项目根目录下的`data`文件夹中，以`.json`和`.csv`格式呈现。
- **爬取限制**：请注意，即使提供了Cookie，由于网站限制，通常最多只能爬取到400条左右的评论。在未提供有效Cookie的情况下，这个限制会更严格（通常最多100条）。
- **应对人机验证**：如果在爬取过程中遇到403错误或程序中断，很可能是你的IP被识别为机器人。此时，最有效的解决方法是手动在浏览器中访问豆瓣网站，完成人机验证，或者更换一个有效的登录Cookie。